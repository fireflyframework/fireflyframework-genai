import type { Node, Edge } from '@xyflow/svelte';

export interface PipelineTemplate {
	id: string;
	name: string;
	description: string;
	/** If set, the template is generated by The Architect via this prompt. */
	architectPrompt?: string;
	/** Static nodes/edges for templates that load directly (e.g. blank). */
	nodes: Node[];
	edges: Edge[];
}

export const PIPELINE_TEMPLATES: PipelineTemplate[] = [
	{
		id: 'blank',
		name: 'Blank Canvas',
		description: 'Start with an empty canvas and build from scratch',
		nodes: [],
		edges: []
	},
	{
		id: 'simple-qa',
		name: 'Q&A Agent',
		description: 'A conversational agent with web search capabilities',
		architectPrompt:
			'Build a simple Q&A agent pipeline. Create one agent node with clear instructions for answering user questions helpfully and concisely. Connect it to a search tool so it can look up information when needed. Configure the agent with a good model and detailed instructions.',
		nodes: [],
		edges: []
	},
	{
		id: 'multi-agent',
		name: 'Multi-Agent Team',
		description: 'Multiple specialized agents that collaborate on complex tasks',
		architectPrompt:
			'Build a multi-agent team pipeline with 3 specialized agents: (1) a Router agent that analyzes the incoming request and decides which specialist to delegate to, (2) a Research agent that gathers information using search tools, and (3) a Writer agent that produces the final polished output. Connect the Router to a condition node that branches to the appropriate specialist based on the task type. Connect both specialists to a final output. Configure every agent with proper model, instructions, and description.',
		nodes: [],
		edges: []
	},
	{
		id: 'rag-pipeline',
		name: 'RAG Pipeline',
		description: 'Retrieval-augmented generation with context injection',
		architectPrompt:
			'Build a RAG (Retrieval-Augmented Generation) pipeline. Create: (1) an Input node for receiving queries, (2) a Retrieval agent that searches a knowledge base for relevant context, (3) a Reasoning node using chain_of_thought to synthesize the retrieved information, (4) a Generator agent that produces a well-grounded answer using the retrieved context, and (5) an Output node for the final response. Connect them in sequence. Configure all agents with proper models and instructions that emphasize grounding answers in retrieved context.',
		nodes: [],
		edges: []
	},
	{
		id: 'reasoning-pipeline',
		name: 'Reasoning Chain',
		description: 'Multi-step reasoning with quality validation and retry logic',
		architectPrompt:
			'Build a reasoning pipeline with quality control. Create: (1) an Input agent that receives and preprocesses user questions, (2) a Reasoning node using chain_of_thought pattern with maxSteps=5, (3) a Validator node that checks the reasoning output is not empty, (4) a Condition node that branches on quality: if valid, route to the Output agent; if invalid, route to a Retry agent that attempts the question with a different approach. Connect the Retry agent back to the Reasoning node for another pass. Configure all agents with proper models and detailed instructions.',
		nodes: [],
		edges: []
	},
	{
		id: 'content-pipeline',
		name: 'Content Generator',
		description: 'Research, draft, and review content with quality checks',
		architectPrompt:
			'Build a content generation pipeline with three stages: (1) a Research agent that gathers information on a topic using search tools, (2) a Writer agent that drafts content based on the research, and (3) a Reviewer agent that critiques the draft for accuracy, clarity, and completeness. Add a Reasoning node with reflexion pattern between the Writer and Reviewer for self-improvement. Add a Validator node after the Reviewer to ensure the output meets quality standards. Configure all agents with proper models, detailed instructions about their specific role, and descriptions.',
		nodes: [],
		edges: []
	},
	{
		id: 'data-processing',
		name: 'Data Processor',
		description: 'Extract, transform, and validate structured data from text',
		architectPrompt:
			'Build a data processing pipeline. Create: (1) an Input node with trigger_type="manual", (2) an Extractor agent that receives unstructured text and extracts structured data fields, (3) a Validator node to ensure extracted data is valid, (4) a Custom Code node for any data transformation logic (provide a placeholder async def execute function), (5) an Output node with destination_type="response". Connect them in sequence. Configure the Extractor agent with detailed instructions about what fields to extract and expected formats.',
		nodes: [],
		edges: []
	},
	{
		id: 'parallel-analysis',
		name: 'Parallel Analysis',
		description: 'Fan-out to multiple analysts, then merge their results',
		architectPrompt:
			'Build a parallel analysis pipeline using fan-out/fan-in pattern. Create: (1) a Coordinator agent that receives a complex question, (2) a Fan-Out node that splits the work, (3) three parallel Agent nodes: a Technical Analyst, a Business Analyst, and a Risk Analyst, each with specialized instructions for their domain, (4) a Fan-In node with merge_expression="collect" to gather all results, and (5) a Synthesizer agent that combines the parallel analyses into a unified report. Connect them properly: Coordinator to Fan-Out, Fan-Out to all three analysts, all three analysts to Fan-In, Fan-In to Synthesizer. Configure every agent with a proper model and role-specific instructions.',
		nodes: [],
		edges: []
	}
];
